# Technical Specification: PolyWeather Minimal Dashboard (Vue 3 + Python)

**Version:** 0.2.5
**Scope:** Single-page, minimal, modern dashboard for Seoul (RKSI) daily high temperature market.

## 1. Goals
- Show **30-minute actual** temperature for the current local day in Seoul (bucketed from METAR).
- Show **real-time market prices** for today’s Seoul highest-temperature event (auto-detect slug).
- Fetch **personal data** (CLOB collateral balance and open positions) but do not display it in v2 UI.
- Persist weather + market telemetry to **Supabase (Postgres)** to support decision-making analytics (forecast accuracy, reaction latency, liquidity) and future automation.
- Keep UI minimal and readable; no trading actions in v2.

## 2. Architecture
### 2.1 Frontend
- **Framework:** Vue 3 (Vite build).
- **Layout:** single page with 2 panels: Weather and Market.
- **Polling:** every **30s** for unified dashboard payload (configurable). Server-side caching ensures weather/portfolio/forecast are not refetched at this cadence.
- **Charts:** line chart with two actual series (AWC + CheckWX); optional overlay of forecast models later.
- **Dev Proxy:** Vite proxies `/api` to the local backend on port 3000.

### 2.2 Backend
- **Framework:** Python (FastAPI) as a thin proxy and aggregator.
- **Reasoning:** keeps API keys private, simplifies CORS, easy scheduled caching.
- **Security:** secrets stored in `.env`; never exposed to client.
- **CLOB Client:** use the official Polymarket Python CLOB client for authenticated balance.
- **Persistence:** when configured, write telemetry to **Supabase** (server-side only).

### 2.3 Persistence (Supabase)
- **DB:** Supabase Postgres is the system of record for time-series telemetry and (later) trading decisions/fills.
- **Write path:** backend writes using the Supabase **service role** key (or direct Postgres connection); frontend never talks to Supabase directly.
- **Design:** append-only inserts for auditability; compute derived metrics via SQL views/queries or periodic jobs.
- **Volume:** at 30s market snapshots, ~2,880 rows/day per outcome; plan retention/downsampling accordingly.
- **Timestamps:** store instants as `timestamptz` (UTC). Store the market’s *KST calendar day* separately as `date_kst` for event grouping.
- **Retention:** keep raw `market_snapshots` for 30–90 days, then downsample to 5m/15m buckets for long-range analytics.
- **Local dev:** Supabase Local config + migrations live in `supabase/` (see `specs/supabase.md`).

## 3. Data Sources
### 3.1 Actuals (METAR)
- **Provider:** Aviation Weather Center.
- **Endpoint:** `https://aviationweather.gov/api/data/metar`
- **Parameters:** `ids=RKSI`, `format=json`, `hours=24`.
- **Companion source:** CheckWX decoded METARs (same station) for side-by-side validation.
  - **Endpoint:** `https://api.checkwx.com/metar/RKSI/decoded`
  - **Auth:** `X-API-Key` header.
  - **Decoded fields:** `observed` timestamp + `temperature.celsius`.

### 3.2 Market Data
- **Gamma API (event discovery):** `https://gamma-api.polymarket.com`
- **CLOB API (prices):** `https://clob.polymarket.com`
- **Data API (positions/activity):** `https://data-api.polymarket.com`

### 3.3 Forecasts (Hourly, decision support)
- **Goal:** store hourly forecast temperature for RKSI so we can compare models and lead times.
- **Providers:**
  - **AviationWeather.gov (free, no key):** RKSI **TAF** (forecast product).
    - TAF: `https://aviationweather.gov/api/data/taf?ids=RKSI&format=json`
    - Note: the METAR endpoint is **observations only** (see §3.1). TAF is not strictly an hourly temperature forecast; store it as raw + parsed features for later use.
  - **Open-Meteo KMA (free for non-commercial, no key):** hourly `temperature_2m` from KMA models.
    - Example: `https://api.open-meteo.com/v1/forecast?hourly=temperature_2m&latitude=37.4625&longitude=126.4392&models=kma_seamless`
    - Models to evaluate: `kma_seamless`, `kma_gdps`, `kma_ldps`.
- **Requirement:** every forecast fetch is stored as an immutable “run” + hourly values (see Supabase schema).

## 4. Event Auto-Detection
- Use **local date in Asia/Seoul** to compute slug:
  - `highest-temperature-in-seoul-on-{month}-{day}`
  - Month is lowercase full name (e.g., `january`), day is numeric (no zero padding).
- Flow:
  1) Build slug from KST date.
  2) Query Gamma event by slug (prefer `/events/slug/{slug}`; fallback to `/events?slug=...`).
  3) Extract `markets[]` and `clobTokenIds` from response.
  4) If missing, show "no event found" state and last successful slug.

## 5. Data Normalization
### 5.1 Time Axis (KST)
- All timestamps displayed in **Asia/Seoul**.
- Actual series aligned to **30-minute ticks** (00:00–23:30 local).

### 5.2 Actuals (METAR) to 30-Minute Buckets
- METAR observations are irregular; derive 30-minute actuals as:
  - For each 30-minute tick, use the **most recent METAR reading at or before** that tick.
  - If no reading exists for an hour, leave it null (gap in chart).
  - Hours after the current KST time should remain null.
  - Only readings from the current local day should be used.

### 5.3 Day High So Far
- Compute **max actual temperature since local 00:00** and display prominently.

## 6. Backend API (internal)
- `GET /api/dashboard`
  - Returns a single payload for the frontend containing:
    - `meta`: last refresh, KST date, slug, and upstream health.
    - `weather`: 30-minute actual arrays for both AWC + CheckWX and source comparison.
    - `market`: list of outcomes with Yes/No prices and recent volume.
    - `forecast`: latest forecast run payload (Open-Meteo KMA models).
    - `portfolio`: balance, positions.
  - Weather payload details:
    - `weather.hourly.times`: 48 half-hour ticks in KST.
    - `weather.hourly.awc`: 30-minute actuals from Aviation Weather Center.
    - `weather.hourly.checkwx`: 30-minute actuals from CheckWX.
    - `weather.sources`: latest/dayHigh per source plus `match` and `delta` for comparison.
      - `weather.sources.{awc|checkwx}.latestObservedAt`: latest METAR observation timestamp (KST ISO).
      - `weather.sources.match`/`delta` are computed **only when both sources share the same** `latestObservedAt`; otherwise they are `null` (staleness, not disagreement).
  - Health payload details:
    - `meta.health`: `{ [source]: { lastSuccessAt, lastError, lastErrorAt } }` (UTC ISO timestamps).
  - Forecast payload details:
    - `forecast.models`: list of KMA model ids (e.g. `kma_seamless`, `kma_gdps`, `kma_ldps`).
    - `forecast.defaultModel`: model to treat as default in UI calculations.
    - `forecast.hourly.times`: hourly timestamps (strings) in `forecast.timezone`.
    - `forecast.hourly.temp_c_by_model`: `{ [model]: number[] }` aligned to `forecast.hourly.times`.
  - **Fetch behavior:** `/api/dashboard` does **not** trigger upstream fetches; it serves the latest in-memory state produced by background ingestion loops. Supabase is for persistence/analytics (and optional “last known good” fallback), not the primary read path.

### 6.1 External Requests (backend only)
- **Actuals:** METAR last 24h from Aviation Weather Center + CheckWX decoded METARs.
- **Market:** Gamma event -> CLOB order book (best ask) by token id (Yes + No).
  - If the order book is missing/unavailable, fallback to Gamma `outcomePrices` (map to YES/NO); otherwise keep prices null and rely on `raw`.
  - Include `volume24hr` from Gamma when available.
- **Portfolio:** CLOB balance + Data API positions.

### 6.2 Ingestion Cadence
- Background pollers use **different cadences per upstream** to support fast market updates without spamming slower weather/portfolio APIs.
- `/api/dashboard` serves the latest aggregated state (read-only).
- CheckWX usage notes:
  - Free plan includes **3,000 daily requests** (10 METAR endpoints); daily counter resets at **00:00 UTC**.
  - 15-minute polling (recommended) ≈ **96 requests/day**, within the free plan budget.
  - CheckWX recommends caching METAR/TAF responses for **at least 15 minutes** and returns **429** when daily limits are exceeded.

Recommended TTLs / cadences:
- **CLOB prices (order book top-of-book):** 30s (`MARKET_TTL_SECONDS=30`)
- **AviationWeather METAR (AWC):** 60s (`AWC_TTL_SECONDS=60`)
- **CheckWX METAR (decoded):** 900s (`CHECK_WX_TTL_SECONDS=900`)
- **Gamma event metadata:** 900s (`EVENT_TTL_SECONDS=900`)
- **Portfolio (balance/positions):** 900–3600s (`PORTFOLIO_TTL_SECONDS=900`)
- **Forecast runs (Open‑Meteo):** 3600s (`FORECAST_TTL_SECONDS=3600`)

### 6.3 Telemetry Logging (Supabase)
- **Purpose:** decision support and future automation should be driven by measured data (not assumptions).
- **Writes are optional:** if Supabase env vars are missing, backend runs in “stateless dashboard” mode.
- **On each poll cycle (cadence depends on upstream):**
  - Upsert the current day’s `events` row (slug/date_kst/first_seen_at).
  - Upsert `event_markets` for the event (group item title/threshold + parsed bounds + token ids).
  - Insert a `market_snapshots` row per outcome **every 30s**.
  - Insert `weather_metar_obs` **only when a new observation timestamp appears** (enforced by unique constraint) and update `weather_day_high_changes` when the day-high increases.
- **Event discovery tracking (new day availability + initial prices):**
  - Poll for “tomorrow’s” slug; when it first appears, create the `events` row and set `events.first_seen_at`.
  - Immediately snapshot all outcomes to capture the **initial** bid/ask distribution.

## 7. Portfolio Data
- **Balance:** CLOB collateral balance (USDC) via authenticated CLOB request.
- **Positions:** Data API `GET /positions?user=...`.

## 8. UI Layout (Minimal)
- **Header:**
  - Title: “Seoul Daily High (RKSI)”
  - Current KST date
  - Last refresh time
  - Day high so far
- **Weather panel:**
  - Line chart: Actual (AWC + CheckWX) with hover tooltip (time + temperature) and labeled axes.
  - Small legend showing both sources and whether they match.
- **Market panel:**
  - Table of outcomes: label, Yes/No prices; highlight outcome matching day high so far
- **Notifications:**
  - Notify (toast + browser notification when permitted) when a new day-high temperature is reached.
  - Optional in-app sound alert enabled by user click.
- **Portfolio panel:** not shown in v2 UI (data still available in payload).

## 9. Configuration (.env)
- `SEOUL_TIMEZONE=Asia/Seoul`
- `MARKET_SLUG_PREFIX=highest-temperature-in-seoul-on`
- `CHECK_WX_API_KEY`
- `CHECK_WX_HOST=https://api.checkwx.com`
- `CHECK_WX_TTL_SECONDS=900`
- `AWC_TTL_SECONDS=60`
- `EVENT_TTL_SECONDS=900`
- `MARKET_TTL_SECONDS=30`
- `PORTFOLIO_TTL_SECONDS=900`
- `FORECAST_TTL_SECONDS=3600`
- `INGESTION_ENABLED=1` (default `1`)
- `RKSI_LAT=37.469`
- `RKSI_LON=126.451`
- `OPEN_METEO_HOST=https://api.open-meteo.com`
- `OPEN_METEO_KMA_MODELS=kma_seamless,kma_gdps,kma_ldps` (recommended)
- `OPEN_METEO_KMA_MODEL=kma_seamless` (sets the default model)
- `OPEN_METEO_FORECAST_DAYS=3`
- `POLYMARKET_USER_ADDRESS`
- `POLYMARKET_PRIVATE_KEY`
- `POLYMARKET_API_KEY`
- `POLYMARKET_API_SECRET`
- `POLYMARKET_API_PASSPHRASE`
- `POLYMARKET_SIGNATURE_TYPE=1`
- `POLYMARKET_FUNDER_ADDRESS`
- `POLYMARKET_CHAIN_ID=137`
- `CACHE_TTL_SECONDS=900` (fallback default when a more specific TTL is not provided)
- `PORT=3000`
- `SUPABASE_URL`
- `SUPABASE_SERVICE_ROLE_KEY`
- `SUPABASE_DB_URL` (optional; use direct Postgres instead of PostgREST)
- `SUPABASE_WRITE_ENABLED=1` (default `0`)

## 10. Security
- Secrets never sent to browser.
- Backend only performs authenticated calls.
- Frontend only hits `/api/dashboard`.
- For Google/Magic login, use proxy wallet auth (signature type `1`) and set `POLYMARKET_FUNDER_ADDRESS` to the proxy wallet address shown on Polymarket.
- Supabase **service role** key stays server-side; do not expose it to the frontend.
- Never store private keys in Supabase; store only public addresses, ids, prices, and telemetry needed for audit/analysis.

## 11. Supabase Schema (Minimal)
Goal: enable queries for:
- Hourly forecast vs actual accuracy (by model + lead time).
- Market reaction latency to new day-high prints (price + liquidity).
- When new-day events appear and their initial pricing.

Decision-support questions this schema should answer:
- At the timestamp a new day-high prints, which **below-high** outcomes still have:
  - `YES` bids (so you can sell YES), and/or
  - `NO` asks (so you can buy NO).
- How long after a new day-high prints until:
  - below-high outcomes lose liquidity (bids/asks disappear or spreads blow out), and
  - the new-high outcome reaches price thresholds (e.g. YES best ask ≥ 0.50 / 0.75 / 0.90).
- When the next-day event is first discoverable and what the initial bid/ask distribution looks like.

SQL sketch (paste into Supabase SQL editor and adjust as needed):

```sql
create extension if not exists pgcrypto;

-- NOTE: store instants as timestamptz (UTC); keep the trading day as date_kst.
create table if not exists events (
  id uuid primary key default gen_random_uuid(),
  date_kst date not null,
  slug text not null unique,
  gamma_event_id text null, -- Gamma "event.id"
  first_seen_at timestamptz not null default now(), -- first time our system saw this slug resolve
  last_seen_at timestamptz not null default now(), -- updated on each successful poll
  raw jsonb null -- raw Gamma event payload (GET /events/slug/{slug})
);

create table if not exists event_markets (
  id uuid primary key default gen_random_uuid(),
  event_id uuid not null references events(id) on delete cascade,
  gamma_market_id text not null, -- Gamma "market.id"
  condition_id text null, -- Gamma "conditionId"
  market_slug text null, -- Gamma "slug"
  question text null, -- Gamma "question"
  group_item_title text null, -- Gamma "groupItemTitle" (e.g. "-5°C or below", "1°C or higher")
  group_item_threshold int null, -- Gamma "groupItemThreshold" (ordering within the event)
  lower_bound_celsius int null, -- parsed from group_item_title / question / market_slug
  upper_bound_celsius int null, -- parsed from group_item_title / question / market_slug
  yes_token_id text not null, -- parsed from Gamma clobTokenIds[0]
  no_token_id text not null, -- parsed from Gamma clobTokenIds[1]
  raw jsonb null,
  unique (event_id, gamma_market_id)
);

create table if not exists market_snapshots (
  id bigint generated by default as identity primary key,
  captured_at timestamptz not null default now(),
  event_id uuid not null references events(id) on delete cascade,
  market_id uuid not null references event_markets(id) on delete cascade,
  accepting_orders boolean null, -- Gamma "acceptingOrders" at captured_at
  accepting_orders_timestamp timestamptz null, -- Gamma "acceptingOrdersTimestamp" when present
  yes_best_bid numeric null,
  yes_best_ask numeric null,
  no_best_bid numeric null,
  no_best_ask numeric null,
  yes_bid_size numeric null,
  yes_ask_size numeric null,
  no_bid_size numeric null,
  no_ask_size numeric null,
  volume24h numeric null,
  source text not null, -- e.g. "clob_orderbook", "gamma_fallback"
  raw jsonb null -- raw payloads (e.g. {gamma: ..., clob_yes: ..., clob_no: ...})
);

create index if not exists idx_market_snapshots_market_time
  on market_snapshots (market_id, captured_at desc);

create table if not exists weather_metar_obs (
  id bigint generated by default as identity primary key,
  station text not null default 'RKSI',
  source text not null, -- "awc" | "checkwx"
  observed_at timestamptz not null,
  ingested_at timestamptz not null default now(), -- when our system first saw this observation
  raw_text text null, -- the METAR string when available
  temp_c numeric not null,
  dewpoint_c numeric null,
  wind_dir_deg int null,
  wind_speed_kt int null,
  wind_gust_kt int null,
  pressure_hpa numeric null, -- AWC "altim" (QNH in hPa when available)
  visibility text null, -- AWC "visib" (keep as text, e.g. "6+")
  flight_category text null, -- AWC "fltCat" (VFR/MVFR/IFR/LIFR) when available
  raw jsonb null,
  unique (station, source, observed_at)
);

create index if not exists idx_weather_metar_obs_time
  on weather_metar_obs (station, observed_at desc);

create table if not exists weather_day_high_changes (
  id bigint generated by default as identity primary key,
  station text not null default 'RKSI',
  source text not null,
  date_kst date not null,
  observed_at timestamptz not null,
  previous_high_celsius int null,
  high_celsius int not null,
  unique (station, source, date_kst, high_celsius)
);

create table if not exists forecast_runs (
  id uuid primary key default gen_random_uuid(),
  model text not null,
  station text not null default 'RKSI',
  run_at timestamptz not null default now(),
  source text not null,
  raw jsonb null,
  unique (model, station, run_at)
);

create table if not exists forecast_hourly (
  id bigint generated by default as identity primary key,
  run_id uuid not null references forecast_runs(id) on delete cascade,
  valid_at timestamptz not null,
  temp_c numeric not null,
  unique (run_id, valid_at)
);
```

## 12. Non-Goals (v2)
- No order placement or trading actions.
- No multi-city support.
- No mobile app.

## 13. Open Questions
- Which Open-Meteo KMA models to run in production (and at what cadence) for best daily-max accuracy.
- Retention policy / partitioning strategy once snapshot volume grows.
